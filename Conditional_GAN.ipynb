{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision.utils\n",
    "\n",
    "from new_data_loader import get_loader\n",
    "from make_gif import make_gif\n",
    "\n",
    "from DiscrimiatorModule import Discriminator\n",
    "from GeneratorModule import Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_weights(m) :\n",
    "    name = type(m)\n",
    "\n",
    "    if name == nn.Conv3d or name == nn.ConvTranspose2d or name == nn.ConvTranspose3d :\n",
    "        m.weight.data.normal_(0.0, 0.01)\n",
    "        m.bias.data.fill_(0)\n",
    "    elif name == nn.BatchNorm2d or name == nn.BatchNorm3d :\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "pre_train = True\n",
    "\n",
    "batch_size = 64\n",
    "video_size = 64\n",
    "epoch_size = 1000\n",
    "        \n",
    "#check GPU\n",
    "is_gpu = torch.cuda.is_available()\n",
    "print(is_gpu)\n",
    "\n",
    "if is_gpu :\n",
    "    dtype = torch.cuda.FloatTensor\n",
    "else :\n",
    "    dtype = torch.FloatTensor\n",
    "\n",
    "if pre_train :\n",
    "    D = torch.load('D.ckpt').type(dtype)\n",
    "    G = torch.load('G.ckpt').type(dtype)\n",
    "else :\n",
    "    D = Discriminator()\n",
    "    D = D.type(dtype)\n",
    "\n",
    "    G = Generator()\n",
    "    G = G.type(dtype)\n",
    "\n",
    "    D.apply(init_weights)\n",
    "    G.apply(init_weights)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss().type(dtype)\n",
    "\n",
    "d_optimizer = torch.optim.Adam(D.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
    "g_optimizer = torch.optim.Adam(G.parameters(), lr=2e-4, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [264/1000], Iter [0/49], d_loss: 0.4987, g_loss: 7.7083\n",
      "Epoch [264/1000], Iter [1/49], d_loss: 0.0159, g_loss: 9.3092\n",
      "Epoch [264/1000], Iter [2/49], d_loss: 0.5341, g_loss: 5.5646\n",
      "Epoch [264/1000], Iter [3/49], d_loss: 0.0230, g_loss: 3.6369\n",
      "Epoch [264/1000], Iter [4/49], d_loss: 0.1487, g_loss: 7.6690\n",
      "Epoch [264/1000], Iter [5/49], d_loss: 0.7244, g_loss: 2.4736\n",
      "Epoch [264/1000], Iter [6/49], d_loss: 0.1684, g_loss: 3.2955\n",
      "Epoch [264/1000], Iter [7/49], d_loss: 0.2525, g_loss: 8.5487\n",
      "Epoch [264/1000], Iter [8/49], d_loss: 0.0043, g_loss: 8.7568\n",
      "Epoch [264/1000], Iter [9/49], d_loss: 0.3591, g_loss: 5.4538\n",
      "Epoch [264/1000], Iter [10/49], d_loss: 0.0150, g_loss: 4.7448\n",
      "Epoch [264/1000], Iter [11/49], d_loss: 0.2033, g_loss: 5.9525\n",
      "Epoch [264/1000], Iter [12/49], d_loss: 0.0252, g_loss: 5.7419\n",
      "Epoch [264/1000], Iter [13/49], d_loss: 0.0515, g_loss: 4.3458\n",
      "Epoch [264/1000], Iter [14/49], d_loss: 0.0060, g_loss: 8.1969\n",
      "Epoch [264/1000], Iter [15/49], d_loss: 0.0219, g_loss: 6.1315\n",
      "Epoch [264/1000], Iter [16/49], d_loss: 0.0414, g_loss: 6.1451\n",
      "Epoch [264/1000], Iter [17/49], d_loss: 0.0136, g_loss: 7.3180\n",
      "Epoch [264/1000], Iter [18/49], d_loss: 0.0491, g_loss: 6.9054\n",
      "Epoch [264/1000], Iter [19/49], d_loss: 0.0209, g_loss: 5.9477\n",
      "Epoch [264/1000], Iter [20/49], d_loss: 0.4289, g_loss: 2.6028\n",
      "Epoch [264/1000], Iter [21/49], d_loss: 0.2847, g_loss: 4.4754\n",
      "Epoch [264/1000], Iter [22/49], d_loss: 0.1769, g_loss: 8.7506\n",
      "Epoch [264/1000], Iter [23/49], d_loss: 0.0247, g_loss: 9.1896\n",
      "Epoch [264/1000], Iter [24/49], d_loss: 0.2610, g_loss: 6.2780\n",
      "Epoch [264/1000], Iter [25/49], d_loss: 0.0452, g_loss: 4.3296\n",
      "Epoch [264/1000], Iter [26/49], d_loss: 0.0985, g_loss: 4.0907\n",
      "Epoch [264/1000], Iter [27/49], d_loss: 0.0937, g_loss: 4.7584\n",
      "Epoch [264/1000], Iter [28/49], d_loss: 0.0528, g_loss: 3.6407\n",
      "Epoch [264/1000], Iter [29/49], d_loss: 0.0557, g_loss: 6.1120\n",
      "Epoch [264/1000], Iter [30/49], d_loss: 0.1155, g_loss: 6.6653\n",
      "Epoch [264/1000], Iter [31/49], d_loss: 0.1593, g_loss: 4.7338\n",
      "Epoch [264/1000], Iter [32/49], d_loss: 0.0451, g_loss: 5.0021\n",
      "Epoch [264/1000], Iter [33/49], d_loss: 0.1504, g_loss: 7.8671\n",
      "Epoch [264/1000], Iter [34/49], d_loss: 0.0119, g_loss: 9.2553\n",
      "Epoch [264/1000], Iter [35/49], d_loss: 0.1530, g_loss: 6.2238\n",
      "Epoch [264/1000], Iter [36/49], d_loss: 0.0335, g_loss: 6.2275\n",
      "Epoch [264/1000], Iter [37/49], d_loss: 0.0212, g_loss: 5.2965\n",
      "Epoch [264/1000], Iter [38/49], d_loss: 0.0644, g_loss: 7.2566\n",
      "Epoch [264/1000], Iter [39/49], d_loss: 0.0347, g_loss: 6.0288\n",
      "Epoch [264/1000], Iter [40/49], d_loss: 0.0677, g_loss: 6.7172\n",
      "Epoch [264/1000], Iter [41/49], d_loss: 0.0074, g_loss: 6.6459\n",
      "Epoch [264/1000], Iter [42/49], d_loss: 0.0401, g_loss: 6.2348\n",
      "Epoch [264/1000], Iter [43/49], d_loss: 0.0848, g_loss: 4.7021\n",
      "Epoch [264/1000], Iter [44/49], d_loss: 0.0240, g_loss: 3.9689\n",
      "Epoch [264/1000], Iter [45/49], d_loss: 0.1843, g_loss: 5.9860\n",
      "Epoch [264/1000], Iter [46/49], d_loss: 0.0578, g_loss: 5.8547\n",
      "Epoch [264/1000], Iter [47/49], d_loss: 0.0454, g_loss: 7.0318\n",
      "Epoch [264/1000], Iter [48/49], d_loss: 0.4243, g_loss: 1.8915\n",
      "Model saving...\n",
      "Epoch [265/1000], Iter [0/49], d_loss: 0.7340, g_loss: 8.8625\n",
      "Epoch [265/1000], Iter [1/49], d_loss: 0.0576, g_loss: 10.2146\n",
      "Epoch [265/1000], Iter [2/49], d_loss: 1.2137, g_loss: 5.2290\n",
      "Epoch [265/1000], Iter [3/49], d_loss: 0.4497, g_loss: 7.2102\n",
      "Epoch [265/1000], Iter [4/49], d_loss: 0.0662, g_loss: 6.5003\n",
      "Epoch [265/1000], Iter [5/49], d_loss: 0.0498, g_loss: 5.7516\n",
      "Epoch [265/1000], Iter [6/49], d_loss: 0.1107, g_loss: 5.4626\n",
      "Epoch [265/1000], Iter [7/49], d_loss: 0.2643, g_loss: 7.8005\n",
      "Epoch [265/1000], Iter [8/49], d_loss: 0.0543, g_loss: 6.7939\n",
      "Epoch [265/1000], Iter [9/49], d_loss: 0.1585, g_loss: 6.1619\n",
      "Epoch [265/1000], Iter [10/49], d_loss: 0.0984, g_loss: 4.9035\n",
      "Epoch [265/1000], Iter [11/49], d_loss: 0.0744, g_loss: 6.5101\n",
      "Epoch [265/1000], Iter [12/49], d_loss: 0.0122, g_loss: 7.1326\n",
      "Epoch [265/1000], Iter [13/49], d_loss: 0.0100, g_loss: 6.1762\n",
      "Epoch [265/1000], Iter [14/49], d_loss: 0.0335, g_loss: 6.2766\n",
      "Epoch [265/1000], Iter [15/49], d_loss: 0.0692, g_loss: 4.3730\n",
      "Epoch [265/1000], Iter [16/49], d_loss: 0.0837, g_loss: 4.7974\n",
      "Epoch [265/1000], Iter [17/49], d_loss: 0.0594, g_loss: 6.9302\n",
      "Epoch [265/1000], Iter [18/49], d_loss: 0.2093, g_loss: 4.0069\n",
      "Epoch [265/1000], Iter [19/49], d_loss: 0.1857, g_loss: 4.3048\n",
      "Epoch [265/1000], Iter [20/49], d_loss: 0.0438, g_loss: 6.8441\n",
      "Epoch [265/1000], Iter [21/49], d_loss: 0.0499, g_loss: 5.1597\n",
      "Epoch [265/1000], Iter [22/49], d_loss: 0.2059, g_loss: 4.4151\n",
      "Epoch [265/1000], Iter [23/49], d_loss: 0.0933, g_loss: 4.9638\n",
      "Epoch [265/1000], Iter [24/49], d_loss: 0.0769, g_loss: 7.9261\n",
      "Epoch [265/1000], Iter [25/49], d_loss: 0.0215, g_loss: 6.7006\n",
      "Epoch [265/1000], Iter [26/49], d_loss: 0.2733, g_loss: 6.3195\n",
      "Epoch [265/1000], Iter [27/49], d_loss: 0.0706, g_loss: 3.5925\n",
      "Epoch [265/1000], Iter [28/49], d_loss: 0.1140, g_loss: 3.7871\n",
      "Epoch [265/1000], Iter [29/49], d_loss: 0.0279, g_loss: 7.1906\n",
      "Epoch [265/1000], Iter [30/49], d_loss: 0.0584, g_loss: 7.4248\n",
      "Epoch [265/1000], Iter [31/49], d_loss: 0.1172, g_loss: 6.1613\n",
      "Epoch [265/1000], Iter [32/49], d_loss: 0.1034, g_loss: 3.3075\n",
      "Epoch [265/1000], Iter [33/49], d_loss: 0.2197, g_loss: 7.1058\n",
      "Epoch [265/1000], Iter [34/49], d_loss: 0.0966, g_loss: 6.5919\n",
      "Epoch [265/1000], Iter [35/49], d_loss: 0.0566, g_loss: 5.4838\n",
      "Epoch [265/1000], Iter [36/49], d_loss: 0.0357, g_loss: 7.0346\n",
      "Epoch [265/1000], Iter [37/49], d_loss: 0.1641, g_loss: 5.0426\n",
      "Epoch [265/1000], Iter [38/49], d_loss: 0.0246, g_loss: 7.5622\n",
      "Epoch [265/1000], Iter [39/49], d_loss: 0.0164, g_loss: 8.1424\n",
      "Epoch [265/1000], Iter [40/49], d_loss: 0.0110, g_loss: 5.6802\n",
      "Epoch [265/1000], Iter [41/49], d_loss: 0.0124, g_loss: 6.5049\n",
      "Epoch [265/1000], Iter [42/49], d_loss: 0.1380, g_loss: 3.3618\n",
      "Epoch [265/1000], Iter [43/49], d_loss: 0.0786, g_loss: 6.7234\n",
      "Epoch [265/1000], Iter [44/49], d_loss: 0.0709, g_loss: 6.7905\n",
      "Epoch [265/1000], Iter [45/49], d_loss: 0.1361, g_loss: 5.7397\n",
      "Epoch [265/1000], Iter [46/49], d_loss: 0.0311, g_loss: 7.7491\n",
      "Epoch [265/1000], Iter [47/49], d_loss: 0.0266, g_loss: 6.4509\n",
      "Epoch [265/1000], Iter [48/49], d_loss: 0.0631, g_loss: 4.6290\n",
      "Model saving...\n",
      "Epoch [266/1000], Iter [0/49], d_loss: 0.0187, g_loss: 3.9165\n",
      "Epoch [266/1000], Iter [1/49], d_loss: 0.0523, g_loss: 4.8399\n",
      "Epoch [266/1000], Iter [2/49], d_loss: 0.0297, g_loss: 4.8390\n",
      "Epoch [266/1000], Iter [3/49], d_loss: 0.0087, g_loss: 4.8476\n",
      "Epoch [266/1000], Iter [4/49], d_loss: 0.0172, g_loss: 4.0091\n",
      "Epoch [266/1000], Iter [5/49], d_loss: 0.0234, g_loss: 5.2773\n",
      "Epoch [266/1000], Iter [6/49], d_loss: 0.0489, g_loss: 4.7505\n",
      "Epoch [266/1000], Iter [7/49], d_loss: 0.0727, g_loss: 3.0453\n",
      "Epoch [266/1000], Iter [8/49], d_loss: 0.0942, g_loss: 6.2279\n",
      "Epoch [266/1000], Iter [9/49], d_loss: 0.7600, g_loss: 0.1210\n",
      "Epoch [266/1000], Iter [10/49], d_loss: 1.5885, g_loss: 13.7533\n",
      "Epoch [266/1000], Iter [11/49], d_loss: 1.0358, g_loss: 6.5385\n",
      "Epoch [266/1000], Iter [12/49], d_loss: 0.4893, g_loss: 3.7386\n",
      "Epoch [266/1000], Iter [13/49], d_loss: 1.6485, g_loss: 13.6149\n",
      "Epoch [266/1000], Iter [14/49], d_loss: 0.3425, g_loss: 12.8873\n",
      "Epoch [266/1000], Iter [15/49], d_loss: 0.1302, g_loss: 10.2943\n",
      "Epoch [266/1000], Iter [16/49], d_loss: 0.2595, g_loss: 10.7919\n",
      "Epoch [266/1000], Iter [17/49], d_loss: 0.4423, g_loss: 5.9281\n",
      "Epoch [266/1000], Iter [18/49], d_loss: 0.0633, g_loss: 3.7745\n",
      "Epoch [266/1000], Iter [19/49], d_loss: 0.1234, g_loss: 5.8198\n",
      "Epoch [266/1000], Iter [20/49], d_loss: 0.1081, g_loss: 9.1318\n",
      "Epoch [266/1000], Iter [21/49], d_loss: 0.1523, g_loss: 6.3441\n",
      "Epoch [266/1000], Iter [22/49], d_loss: 0.0265, g_loss: 4.8860\n",
      "Epoch [266/1000], Iter [23/49], d_loss: 0.0577, g_loss: 7.3847\n",
      "Epoch [266/1000], Iter [24/49], d_loss: 0.0570, g_loss: 5.8661\n",
      "Epoch [266/1000], Iter [25/49], d_loss: 0.0713, g_loss: 5.6845\n",
      "Epoch [266/1000], Iter [26/49], d_loss: 0.1653, g_loss: 9.7493\n",
      "Epoch [266/1000], Iter [27/49], d_loss: 0.1979, g_loss: 6.5423\n",
      "Epoch [266/1000], Iter [28/49], d_loss: 0.0149, g_loss: 6.8950\n",
      "Epoch [266/1000], Iter [29/49], d_loss: 0.0196, g_loss: 5.2279\n",
      "Epoch [266/1000], Iter [30/49], d_loss: 0.2250, g_loss: 8.8623\n",
      "Epoch [266/1000], Iter [31/49], d_loss: 0.0265, g_loss: 11.6040\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [266/1000], Iter [32/49], d_loss: 0.0456, g_loss: 9.2748\n",
      "Epoch [266/1000], Iter [33/49], d_loss: 0.1080, g_loss: 7.9031\n",
      "Epoch [266/1000], Iter [34/49], d_loss: 0.0341, g_loss: 8.0723\n",
      "Epoch [266/1000], Iter [35/49], d_loss: 0.0206, g_loss: 6.2563\n",
      "Epoch [266/1000], Iter [36/49], d_loss: 0.1554, g_loss: 5.5564\n",
      "Epoch [266/1000], Iter [37/49], d_loss: 0.1977, g_loss: 7.8398\n",
      "Epoch [266/1000], Iter [38/49], d_loss: 0.0295, g_loss: 8.8001\n",
      "Epoch [266/1000], Iter [39/49], d_loss: 0.1030, g_loss: 8.5424\n",
      "Epoch [266/1000], Iter [40/49], d_loss: 0.0268, g_loss: 6.7837\n",
      "Epoch [266/1000], Iter [41/49], d_loss: 0.0600, g_loss: 7.0566\n",
      "Epoch [266/1000], Iter [42/49], d_loss: 0.0441, g_loss: 8.5073\n",
      "Epoch [266/1000], Iter [43/49], d_loss: 0.0944, g_loss: 6.2165\n",
      "Epoch [266/1000], Iter [44/49], d_loss: 0.1189, g_loss: 5.1503\n",
      "Epoch [266/1000], Iter [45/49], d_loss: 0.0591, g_loss: 4.5497\n",
      "Epoch [266/1000], Iter [46/49], d_loss: 0.2123, g_loss: 5.0143\n",
      "Epoch [266/1000], Iter [47/49], d_loss: 0.0679, g_loss: 6.0038\n",
      "Epoch [266/1000], Iter [48/49], d_loss: 0.0633, g_loss: 8.0809\n",
      "Model saving...\n",
      "Epoch [267/1000], Iter [0/49], d_loss: 0.1098, g_loss: 6.5513\n",
      "Epoch [267/1000], Iter [1/49], d_loss: 0.0162, g_loss: 6.1885\n",
      "Epoch [267/1000], Iter [2/49], d_loss: 0.0238, g_loss: 4.7256\n",
      "Epoch [267/1000], Iter [3/49], d_loss: 0.1348, g_loss: 5.1149\n",
      "Epoch [267/1000], Iter [4/49], d_loss: 0.1583, g_loss: 2.4631\n",
      "Epoch [267/1000], Iter [5/49], d_loss: 0.2254, g_loss: 8.5544\n",
      "Epoch [267/1000], Iter [6/49], d_loss: 0.1779, g_loss: 6.0982\n",
      "Epoch [267/1000], Iter [7/49], d_loss: 0.0201, g_loss: 6.3406\n",
      "Epoch [267/1000], Iter [8/49], d_loss: 0.0145, g_loss: 5.3514\n",
      "Epoch [267/1000], Iter [9/49], d_loss: 0.0477, g_loss: 6.8207\n",
      "Epoch [267/1000], Iter [10/49], d_loss: 0.0743, g_loss: 6.2365\n",
      "Epoch [267/1000], Iter [11/49], d_loss: 0.0362, g_loss: 4.4104\n",
      "Epoch [267/1000], Iter [12/49], d_loss: 0.0349, g_loss: 6.0139\n",
      "Epoch [267/1000], Iter [13/49], d_loss: 0.0545, g_loss: 6.3475\n",
      "Epoch [267/1000], Iter [14/49], d_loss: 0.0421, g_loss: 6.4788\n",
      "Epoch [267/1000], Iter [15/49], d_loss: 0.0311, g_loss: 6.0290\n",
      "Epoch [267/1000], Iter [16/49], d_loss: 0.0204, g_loss: 5.3241\n",
      "Epoch [267/1000], Iter [17/49], d_loss: 0.2096, g_loss: 4.2359\n",
      "Epoch [267/1000], Iter [18/49], d_loss: 0.5522, g_loss: 9.2637\n",
      "Epoch [267/1000], Iter [19/49], d_loss: 0.2228, g_loss: 8.6088\n",
      "Epoch [267/1000], Iter [20/49], d_loss: 0.0180, g_loss: 8.0307\n",
      "Epoch [267/1000], Iter [21/49], d_loss: 0.4335, g_loss: 6.4722\n",
      "Epoch [267/1000], Iter [22/49], d_loss: 0.0187, g_loss: 4.9036\n",
      "Epoch [267/1000], Iter [23/49], d_loss: 0.2514, g_loss: 5.1807\n",
      "Epoch [267/1000], Iter [24/49], d_loss: 0.0746, g_loss: 6.5033\n",
      "Epoch [267/1000], Iter [25/49], d_loss: 0.0466, g_loss: 8.0831\n",
      "Epoch [267/1000], Iter [26/49], d_loss: 0.0146, g_loss: 7.7712\n",
      "Epoch [267/1000], Iter [27/49], d_loss: 0.1218, g_loss: 7.3090\n",
      "Epoch [267/1000], Iter [28/49], d_loss: 0.0996, g_loss: 6.6614\n",
      "Epoch [267/1000], Iter [29/49], d_loss: 0.0289, g_loss: 7.2316\n",
      "Epoch [267/1000], Iter [30/49], d_loss: 0.0425, g_loss: 5.9339\n",
      "Epoch [267/1000], Iter [31/49], d_loss: 0.0613, g_loss: 5.5719\n",
      "Epoch [267/1000], Iter [32/49], d_loss: 0.0201, g_loss: 4.2165\n",
      "Epoch [267/1000], Iter [33/49], d_loss: 0.0747, g_loss: 6.8566\n",
      "Epoch [267/1000], Iter [34/49], d_loss: 0.0435, g_loss: 7.4848\n",
      "Epoch [267/1000], Iter [35/49], d_loss: 0.1798, g_loss: 4.9475\n",
      "Epoch [267/1000], Iter [36/49], d_loss: 0.0713, g_loss: 5.3833\n",
      "Epoch [267/1000], Iter [37/49], d_loss: 0.0917, g_loss: 6.7965\n",
      "Epoch [267/1000], Iter [38/49], d_loss: 0.0101, g_loss: 7.8265\n",
      "Epoch [267/1000], Iter [39/49], d_loss: 0.2608, g_loss: 4.5532\n",
      "Epoch [267/1000], Iter [40/49], d_loss: 0.0544, g_loss: 4.3036\n",
      "Epoch [267/1000], Iter [41/49], d_loss: 0.2489, g_loss: 9.1121\n",
      "Epoch [267/1000], Iter [42/49], d_loss: 0.0088, g_loss: 10.9433\n",
      "Epoch [267/1000], Iter [43/49], d_loss: 0.7539, g_loss: 2.9224\n",
      "Epoch [267/1000], Iter [44/49], d_loss: 0.5216, g_loss: 8.8410\n",
      "Epoch [267/1000], Iter [45/49], d_loss: 0.0947, g_loss: 11.0707\n",
      "Epoch [267/1000], Iter [46/49], d_loss: 0.1982, g_loss: 6.7888\n",
      "Epoch [267/1000], Iter [47/49], d_loss: 0.0091, g_loss: 7.0573\n",
      "Epoch [267/1000], Iter [48/49], d_loss: 0.1397, g_loss: 4.1005\n",
      "Model saving...\n",
      "Epoch [268/1000], Iter [0/49], d_loss: 0.0966, g_loss: 5.5369\n",
      "Epoch [268/1000], Iter [1/49], d_loss: 0.1013, g_loss: 7.2316\n",
      "Epoch [268/1000], Iter [2/49], d_loss: 0.0417, g_loss: 7.8805\n",
      "Epoch [268/1000], Iter [3/49], d_loss: 0.0650, g_loss: 6.9654\n",
      "Epoch [268/1000], Iter [4/49], d_loss: 0.0111, g_loss: 8.7043\n",
      "Epoch [268/1000], Iter [5/49], d_loss: 0.0503, g_loss: 7.2836\n",
      "Epoch [268/1000], Iter [6/49], d_loss: 0.3403, g_loss: 3.6872\n",
      "Epoch [268/1000], Iter [7/49], d_loss: 0.1755, g_loss: 6.3058\n",
      "Epoch [268/1000], Iter [8/49], d_loss: 0.1171, g_loss: 8.1314\n",
      "Epoch [268/1000], Iter [9/49], d_loss: 0.1889, g_loss: 9.7249\n",
      "Epoch [268/1000], Iter [10/49], d_loss: 0.2114, g_loss: 9.5935\n",
      "Epoch [268/1000], Iter [11/49], d_loss: 0.0704, g_loss: 5.0340\n",
      "Epoch [268/1000], Iter [12/49], d_loss: 0.0755, g_loss: 4.4715\n",
      "Epoch [268/1000], Iter [13/49], d_loss: 0.0974, g_loss: 6.6476\n",
      "Epoch [268/1000], Iter [14/49], d_loss: 0.0187, g_loss: 5.8522\n",
      "Epoch [268/1000], Iter [15/49], d_loss: 0.6978, g_loss: 0.9543\n",
      "Epoch [268/1000], Iter [16/49], d_loss: 1.4112, g_loss: 13.4814\n",
      "Epoch [268/1000], Iter [17/49], d_loss: 0.3846, g_loss: 12.7923\n",
      "Epoch [268/1000], Iter [18/49], d_loss: 0.0824, g_loss: 10.2975\n",
      "Epoch [268/1000], Iter [19/49], d_loss: 0.5962, g_loss: 9.9728\n",
      "Epoch [268/1000], Iter [20/49], d_loss: 0.2701, g_loss: 4.7217\n",
      "Epoch [268/1000], Iter [21/49], d_loss: 0.1665, g_loss: 3.5374\n",
      "Epoch [268/1000], Iter [22/49], d_loss: 0.0203, g_loss: 3.6640\n",
      "Epoch [268/1000], Iter [23/49], d_loss: 0.0340, g_loss: 7.3646\n",
      "Epoch [268/1000], Iter [24/49], d_loss: 0.0809, g_loss: 7.4566\n",
      "Epoch [268/1000], Iter [25/49], d_loss: 0.0373, g_loss: 7.1950\n",
      "Epoch [268/1000], Iter [26/49], d_loss: 0.1914, g_loss: 4.2775\n",
      "Epoch [268/1000], Iter [27/49], d_loss: 0.2371, g_loss: 7.9612\n",
      "Epoch [268/1000], Iter [28/49], d_loss: 0.1472, g_loss: 6.1155\n",
      "Epoch [268/1000], Iter [29/49], d_loss: 0.0499, g_loss: 7.0536\n",
      "Epoch [268/1000], Iter [30/49], d_loss: 0.0077, g_loss: 5.9518\n",
      "Epoch [268/1000], Iter [31/49], d_loss: 0.0697, g_loss: 5.6843\n",
      "Epoch [268/1000], Iter [32/49], d_loss: 0.0339, g_loss: 6.8392\n",
      "Epoch [268/1000], Iter [33/49], d_loss: 0.0271, g_loss: 5.4339\n",
      "Epoch [268/1000], Iter [34/49], d_loss: 0.0270, g_loss: 3.9803\n",
      "Epoch [268/1000], Iter [35/49], d_loss: 0.1108, g_loss: 7.9839\n",
      "Epoch [268/1000], Iter [36/49], d_loss: 0.0664, g_loss: 7.0857\n",
      "Epoch [268/1000], Iter [37/49], d_loss: 0.0087, g_loss: 4.8354\n",
      "Epoch [268/1000], Iter [38/49], d_loss: 0.0278, g_loss: 3.9689\n",
      "Epoch [268/1000], Iter [39/49], d_loss: 0.0540, g_loss: 4.2699\n",
      "Epoch [268/1000], Iter [40/49], d_loss: 0.0309, g_loss: 5.7283\n",
      "Epoch [268/1000], Iter [41/49], d_loss: 0.0858, g_loss: 4.3529\n",
      "Epoch [268/1000], Iter [42/49], d_loss: 0.0706, g_loss: 6.1403\n",
      "Epoch [268/1000], Iter [43/49], d_loss: 0.0397, g_loss: 5.1305\n",
      "Epoch [268/1000], Iter [44/49], d_loss: 0.0204, g_loss: 5.0525\n",
      "Epoch [268/1000], Iter [45/49], d_loss: 0.0267, g_loss: 4.0486\n",
      "Epoch [268/1000], Iter [46/49], d_loss: 0.0474, g_loss: 4.9536\n",
      "Epoch [268/1000], Iter [47/49], d_loss: 0.1672, g_loss: 1.3981\n",
      "Epoch [268/1000], Iter [48/49], d_loss: 0.1260, g_loss: 2.1700\n",
      "Model saving...\n",
      "Epoch [269/1000], Iter [0/49], d_loss: 0.2898, g_loss: 5.6150\n",
      "Epoch [269/1000], Iter [1/49], d_loss: 0.1768, g_loss: 6.4255\n",
      "Epoch [269/1000], Iter [2/49], d_loss: 0.0569, g_loss: 6.4062\n",
      "Epoch [269/1000], Iter [3/49], d_loss: 0.0141, g_loss: 7.4304\n",
      "Epoch [269/1000], Iter [4/49], d_loss: 0.1121, g_loss: 7.8872\n",
      "Epoch [269/1000], Iter [5/49], d_loss: 0.1362, g_loss: 6.1624\n",
      "Epoch [269/1000], Iter [6/49], d_loss: 0.0881, g_loss: 4.9377\n",
      "Epoch [269/1000], Iter [7/49], d_loss: 0.1713, g_loss: 1.2841\n",
      "Epoch [269/1000], Iter [8/49], d_loss: 0.6338, g_loss: 12.4420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-12:\n",
      "Process Process-11:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dskym0/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/dskym0/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/dskym0/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/dskym0/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/dskym0/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dskym0/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/dskym0/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/dskym0/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/dskym0/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 40, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/dskym0/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 40, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/dskym0/KUDL_TermProject/new_data_loader.py\", line 60, in __getitem__\n",
      "    image = self.transform(image)\n",
      "  File \"/home/dskym0/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/dskym0/anaconda3/lib/python3.6/site-packages/torchvision-0.1.9-py3.6.egg/torchvision/transforms.py\", line 34, in __call__\n",
      "    img = t(img)\n",
      "  File \"/home/dskym0/anaconda3/lib/python3.6/site-packages/torchvision-0.1.9-py3.6.egg/torchvision/transforms.py\", line 199, in __call__\n",
      "    return img.resize(self.size, self.interpolation)\n",
      "  File \"/home/dskym0/anaconda3/lib/python3.6/site-packages/PIL/Image.py\", line 1712, in resize\n",
      "    return self._new(self.im.resize(size, resample))\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-cf61381beed7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;31m# 2. Train Generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mfake_videos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_videos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mtype\u001b[0;34m(self, t)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/_functions/tensor.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, i, dest_type)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdest_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36m_type\u001b[0;34m(self, new_type, async)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnew_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sparse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot cast dense tensor to sparse tensor\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_loader = get_loader(data_path='./dataset', image_size=video_size, batch_size=batch_size, num_workers=2)\n",
    "\n",
    "for epoch in range(384, epoch_size + 1) :\n",
    "    for iter, (video, y) in enumerate(data_loader) :\n",
    "        local_batch_size = video.size()[0]\n",
    "        \n",
    "        real_labels = Variable(torch.ones(local_batch_size, 2).type(dtype))\n",
    "        fake_labels = Variable(torch.zeros(local_batch_size, 2).type(dtype))\n",
    "        \n",
    "        # 1. Train Discriminator\n",
    "        video_data = Variable(video).type(dtype)\n",
    "        y = Variable(y).type(dtype)\n",
    "        \n",
    "        y_data = torch.unsqueeze(torch.unsqueeze(torch.unsqueeze(y, -1), -1), -1)\n",
    "        y_data = y_data.expand(local_batch_size, 6, 32, 64, 64)\n",
    "       \n",
    "        \n",
    "        \n",
    "        # 1-1. Real Video\n",
    "        outputs = D(video_data, y_data).view(local_batch_size, 2)\n",
    "        d_loss_real = criterion(outputs, real_labels)\n",
    "\n",
    "        \n",
    "        \n",
    "        # 1-2. Fake Video\n",
    "        z = Variable(torch.randn(local_batch_size, 100) * 0.01).type(dtype)\n",
    "        fake_videos = G(z, y)\n",
    "        outputs = D(fake_videos, y_data).view(local_batch_size, 2)\n",
    "        d_loss_fake = criterion(outputs, fake_labels)\n",
    "\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        \n",
    "        D.zero_grad()\n",
    "        G.zero_grad()\n",
    "        d_loss.backward()\n",
    "        d_optimizer.step()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # 2. Train Generator\n",
    "        z = Variable(torch.randn(local_batch_size, 100) * 0.01).type(dtype)\n",
    "        fake_videos = G(z, y)\n",
    "        outputs = D(fake_videos, y_data).view(local_batch_size, 2)\n",
    "\n",
    "        g_loss = criterion(outputs, real_labels)\n",
    "        D.zero_grad()\n",
    "        G.zero_grad()\n",
    "\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "          \n",
    "        print('Epoch [%d/%d], Iter [%d/%d], d_loss: %.4f, g_loss: %.4f' % (epoch, epoch_size, iter, len(data_loader), d_loss.data[0], g_loss.data[0]))\n",
    "    \n",
    "    print('Model saving...')\n",
    "    \n",
    "    torch.save(D, 'D.ckpt')\n",
    "    torch.save(G, 'G.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
