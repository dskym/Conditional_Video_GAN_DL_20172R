{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision.utils\n",
    "\n",
    "from new_data_loader import get_loader\n",
    "from make_gif import make_gif\n",
    "\n",
    "from DiscrimiatorModule import Discriminator\n",
    "from GeneratorModule import Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_weights(m) :\n",
    "    name = type(m)\n",
    "\n",
    "    if name == nn.Conv3d or name == nn.ConvTranspose2d or name == nn.ConvTranspose3d :\n",
    "        m.weight.data.normal_(0.0, 0.01)\n",
    "        m.bias.data.fill_(0)\n",
    "    elif name == nn.BatchNorm2d or name == nn.BatchNorm3d :\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "pre_train = True\n",
    "\n",
    "batch_size = 64\n",
    "video_size = 64\n",
    "epoch_size = 1000\n",
    "        \n",
    "#check GPU\n",
    "is_gpu = torch.cuda.is_available()\n",
    "print(is_gpu)\n",
    "\n",
    "if is_gpu :\n",
    "    dtype = torch.cuda.FloatTensor\n",
    "else :\n",
    "    dtype = torch.FloatTensor\n",
    "\n",
    "if pre_train :\n",
    "    D = torch.load('D.ckpt').type(dtype)\n",
    "    G = torch.load('G.ckpt').type(dtype)\n",
    "else :\n",
    "    D = Discriminator()\n",
    "    D = D.type(dtype)\n",
    "\n",
    "    G = Generator()\n",
    "    G = G.type(dtype)\n",
    "\n",
    "    D.apply(init_weights)\n",
    "    G.apply(init_weights)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss().type(dtype)\n",
    "\n",
    "d_optimizer = torch.optim.Adam(D.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
    "g_optimizer = torch.optim.Adam(G.parameters(), lr=2e-4, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [384/1000], Iter [0/49], d_loss: 0.2224, g_loss: 2.0415\n",
      "Epoch [384/1000], Iter [1/49], d_loss: 0.1755, g_loss: 6.3966\n",
      "Epoch [384/1000], Iter [2/49], d_loss: 0.0084, g_loss: 9.1431\n",
      "Epoch [384/1000], Iter [3/49], d_loss: 0.0066, g_loss: 8.1735\n",
      "Epoch [384/1000], Iter [4/49], d_loss: 0.0121, g_loss: 7.2475\n",
      "Epoch [384/1000], Iter [5/49], d_loss: 0.0454, g_loss: 8.9441\n",
      "Epoch [384/1000], Iter [6/49], d_loss: 0.0042, g_loss: 8.0692\n",
      "Epoch [384/1000], Iter [7/49], d_loss: 0.0257, g_loss: 8.9309\n",
      "Epoch [384/1000], Iter [8/49], d_loss: 0.0479, g_loss: 6.7944\n",
      "Epoch [384/1000], Iter [9/49], d_loss: 0.0291, g_loss: 6.1598\n",
      "Epoch [384/1000], Iter [10/49], d_loss: 0.0217, g_loss: 8.0372\n",
      "Epoch [384/1000], Iter [11/49], d_loss: 0.0011, g_loss: 8.1110\n",
      "Epoch [384/1000], Iter [12/49], d_loss: 0.0019, g_loss: 6.4925\n",
      "Epoch [384/1000], Iter [13/49], d_loss: 0.0156, g_loss: 6.9862\n",
      "Epoch [384/1000], Iter [14/49], d_loss: 0.0098, g_loss: 5.9769\n",
      "Epoch [384/1000], Iter [15/49], d_loss: 0.0238, g_loss: 7.0272\n",
      "Epoch [384/1000], Iter [16/49], d_loss: 0.0288, g_loss: 7.7801\n",
      "Epoch [384/1000], Iter [17/49], d_loss: 0.0216, g_loss: 6.5613\n",
      "Epoch [384/1000], Iter [18/49], d_loss: 0.0026, g_loss: 8.4501\n",
      "Epoch [384/1000], Iter [19/49], d_loss: 0.0031, g_loss: 6.4235\n",
      "Epoch [384/1000], Iter [20/49], d_loss: 0.0779, g_loss: 5.0724\n",
      "Epoch [384/1000], Iter [21/49], d_loss: 0.4145, g_loss: 14.5950\n",
      "Epoch [384/1000], Iter [22/49], d_loss: 0.1786, g_loss: 14.8406\n",
      "Epoch [384/1000], Iter [23/49], d_loss: 0.2436, g_loss: 10.7386\n",
      "Epoch [384/1000], Iter [24/49], d_loss: 0.0602, g_loss: 7.0383\n",
      "Epoch [384/1000], Iter [25/49], d_loss: 0.0119, g_loss: 3.7024\n",
      "Epoch [384/1000], Iter [26/49], d_loss: 0.0162, g_loss: 4.6126\n",
      "Epoch [384/1000], Iter [27/49], d_loss: 0.2497, g_loss: 12.3453\n",
      "Epoch [384/1000], Iter [28/49], d_loss: 0.0047, g_loss: 16.3610\n",
      "Epoch [384/1000], Iter [29/49], d_loss: 0.9530, g_loss: 6.5463\n",
      "Epoch [384/1000], Iter [30/49], d_loss: 0.0345, g_loss: 5.4399\n",
      "Epoch [384/1000], Iter [31/49], d_loss: 0.4300, g_loss: 10.2230\n",
      "Epoch [384/1000], Iter [32/49], d_loss: 0.0949, g_loss: 12.2358\n",
      "Epoch [384/1000], Iter [33/49], d_loss: 0.1840, g_loss: 11.4824\n",
      "Epoch [384/1000], Iter [34/49], d_loss: 0.0068, g_loss: 11.0153\n",
      "Epoch [384/1000], Iter [35/49], d_loss: 0.0676, g_loss: 8.0501\n",
      "Epoch [384/1000], Iter [36/49], d_loss: 0.0103, g_loss: 5.7644\n",
      "Epoch [384/1000], Iter [37/49], d_loss: 0.0159, g_loss: 6.2542\n",
      "Epoch [384/1000], Iter [38/49], d_loss: 0.0175, g_loss: 5.7522\n",
      "Epoch [384/1000], Iter [39/49], d_loss: 0.5253, g_loss: 12.2313\n",
      "Epoch [384/1000], Iter [40/49], d_loss: 0.3555, g_loss: 11.4400\n",
      "Epoch [384/1000], Iter [41/49], d_loss: 0.0316, g_loss: 11.0864\n",
      "Epoch [384/1000], Iter [42/49], d_loss: 0.0392, g_loss: 9.1037\n",
      "Epoch [384/1000], Iter [43/49], d_loss: 0.1266, g_loss: 7.0958\n",
      "Epoch [384/1000], Iter [44/49], d_loss: 0.0478, g_loss: 9.1499\n",
      "Epoch [384/1000], Iter [45/49], d_loss: 0.0169, g_loss: 9.2950\n",
      "Epoch [384/1000], Iter [46/49], d_loss: 0.0855, g_loss: 6.6721\n",
      "Epoch [384/1000], Iter [47/49], d_loss: 0.0179, g_loss: 8.1637\n",
      "Epoch [384/1000], Iter [48/49], d_loss: 0.1955, g_loss: 6.3456\n",
      "Model saving...\n",
      "Epoch [385/1000], Iter [0/49], d_loss: 0.1302, g_loss: 6.2611\n",
      "Epoch [385/1000], Iter [1/49], d_loss: 0.0523, g_loss: 6.6361\n",
      "Epoch [385/1000], Iter [2/49], d_loss: 0.0080, g_loss: 8.2147\n",
      "Epoch [385/1000], Iter [3/49], d_loss: 0.1049, g_loss: 5.4650\n",
      "Epoch [385/1000], Iter [4/49], d_loss: 0.0243, g_loss: 5.8874\n",
      "Epoch [385/1000], Iter [5/49], d_loss: 0.0588, g_loss: 7.9329\n",
      "Epoch [385/1000], Iter [6/49], d_loss: 0.0182, g_loss: 7.8976\n",
      "Epoch [385/1000], Iter [7/49], d_loss: 0.0810, g_loss: 6.5765\n",
      "Epoch [385/1000], Iter [8/49], d_loss: 0.0063, g_loss: 6.0501\n",
      "Epoch [385/1000], Iter [9/49], d_loss: 0.0219, g_loss: 5.4023\n"
     ]
    }
   ],
   "source": [
    "data_loader = get_loader(data_path='./dataset', image_size=video_size, batch_size=batch_size, num_workers=2)\n",
    "\n",
    "for epoch in range(384, epoch_size + 1) :\n",
    "    for iter, (video, y) in enumerate(data_loader) :\n",
    "        local_batch_size = video.size()[0]\n",
    "        \n",
    "        real_labels = Variable(torch.ones(local_batch_size, 2).type(dtype))\n",
    "        fake_labels = Variable(torch.zeros(local_batch_size, 2).type(dtype))\n",
    "        \n",
    "        # 1. Train Discriminator\n",
    "        video_data = Variable(video).type(dtype)\n",
    "        y = Variable(y).type(dtype)\n",
    "        \n",
    "        y_data = torch.unsqueeze(torch.unsqueeze(torch.unsqueeze(y, -1), -1), -1)\n",
    "        y_data = y_data.expand(local_batch_size, 6, 32, 64, 64)\n",
    "       \n",
    "        \n",
    "        \n",
    "        # 1-1. Real Video\n",
    "        outputs = D(video_data, y_data).view(local_batch_size, 2)\n",
    "        d_loss_real = criterion(outputs, real_labels)\n",
    "\n",
    "        \n",
    "        \n",
    "        # 1-2. Fake Video\n",
    "        z = Variable(torch.randn(local_batch_size, 100) * 0.01).type(dtype)\n",
    "        fake_videos = G(z, y)\n",
    "        outputs = D(fake_videos, y_data).view(local_batch_size, 2)\n",
    "        d_loss_fake = criterion(outputs, fake_labels)\n",
    "\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        \n",
    "        D.zero_grad()\n",
    "        G.zero_grad()\n",
    "        d_loss.backward()\n",
    "        d_optimizer.step()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # 2. Train Generator\n",
    "        z = Variable(torch.randn(local_batch_size, 100) * 0.01).type(dtype)\n",
    "        fake_videos = G(z, y)\n",
    "        outputs = D(fake_videos, y_data).view(local_batch_size, 2)\n",
    "\n",
    "        g_loss = criterion(outputs, real_labels)\n",
    "        D.zero_grad()\n",
    "        G.zero_grad()\n",
    "\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "          \n",
    "        print('Epoch [%d/%d], Iter [%d/%d], d_loss: %.4f, g_loss: %.4f' % (epoch, epoch_size, iter, len(data_loader), d_loss.data[0], g_loss.data[0]))\n",
    "    \n",
    "    print('Model saving...')\n",
    "    \n",
    "    torch.save(D, 'D.ckpt')\n",
    "    torch.save(G, 'G.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
